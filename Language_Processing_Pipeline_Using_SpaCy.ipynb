{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c50bff0",
   "metadata": {},
   "source": [
    "In NLP, \"nlp.pipeline\" refers to a series of processing steps that are applied to raw text data to perform specific NLP tasks. The outputs of the pipeline can vary depending on the components included, but some common outputs include:\n",
    "\n",
    "- tok2vec: This is a vector representation of a token (word, phrase, etc.), often generated using techniques such as word embeddings or sentence embeddings. The goal of tok2vec is to capture the semantic meaning of the token in a numerical format that can be used by NLP algorithms.\n",
    "\n",
    "- Tagger: A part-of-speech (POS) tagger is an NLP component that labels each token in a sentence with its corresponding part of speech (e.g., noun, verb, adjective, etc.). The tagger helps to understand the structure of the sentence and identify important words and phrases.\n",
    "\n",
    "- Parser: A parser is an NLP component that analyzes the grammatical structure of a sentence to determine the relationships between its components. Parsing can provide information about the subject-verb relationships, noun phrases, and other linguistic features of a sentence.\n",
    "\n",
    "- Named Entity Recognizer (NER): An NER is an NLP component that identifies named entities, such as people, organizations, and locations, in a text. NER can be useful for information extraction, question answering, and other NLP tasks.\n",
    "\n",
    "- Dependency Parser: A dependency parser is an NLP component that determines the dependencies between words in a sentence. The parser can provide information about the relationships between words, such as subject-verb relationships, and can be useful for understanding the meaning of a sentence.\n",
    "\n",
    "- Sentiment Analyzer: A sentiment analyzer is an NLP component that determines the sentiment expressed in a text. Sentiment analysis can be used to identify the overall mood or tone of a text and can be applied to various tasks, such as opinion mining, product reviews, and social media analysis.\n",
    "\n",
    "- Text Classifier: A text classifier is an NLP component that assigns predefined categories or labels to a given text. Text classification can be used for tasks such as spam detection, sentiment analysis, and topic classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cba91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9837a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanuman\n",
      "can\n",
      "swim\n",
      "the\n",
      "sea\n",
      "in\n",
      "30\n",
      "hours\n",
      ".\n",
      "It\n",
      "took\n",
      "him\n",
      "2\n",
      "days\n",
      "from\n",
      "USA\n",
      "to\n",
      "India\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"Hanuman can swim the sea in 30 hours. It took him 2 days from USA to India.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd72bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ddb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download en_core_web_sm(pytohn -m spacy download en_core_web_sm) -> a pre-trained pipeline for English language \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ddea550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x17b7974bfa0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x17b7974bee0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x17b7b8e2f90>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x17b7baa1780>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x17b7baee800>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x17b7b8e2d60>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f70620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanuman  |  PROPN  |  Hanuman\n",
      "can  |  AUX  |  can\n",
      "swim  |  VERB  |  swim\n",
      "the  |  DET  |  the\n",
      "sea  |  NOUN  |  sea\n",
      "in  |  ADP  |  in\n",
      "30  |  NUM  |  30\n",
      "hours  |  NOUN  |  hour\n",
      ".  |  PUNCT  |  .\n",
      "It  |  PRON  |  it\n",
      "took  |  VERB  |  take\n",
      "him  |  PRON  |  he\n",
      "2  |  NUM  |  2\n",
      "days  |  NOUN  |  day\n",
      "from  |  ADP  |  from\n",
      "USA  |  PROPN  |  USA\n",
      "to  |  ADP  |  to\n",
      "India  |  PROPN  |  India\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hanuman can swim the sea in 30 hours. It took him 2 days from USA to India.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \", token.pos_, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d69133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tata Group  |  ORG\n",
      "Jaguar Cars  |  ORG\n",
      "$2.3 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tata Group had bought Jaguar Cars for $2.3 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320d0996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tata Group  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Jaguar Cars  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$2.3 billion  |  MONEY  |  Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tata Group had bought Jaguar Cars for $2.3 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6067ba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tata Group\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " had bought \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jaguar Cars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $2.3 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To display the statement\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2044dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tata  |  PERSON  |  People, including fictional\n",
      "Tata Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "1868  |  DATE  |  Absolute or relative dates or periods\n",
      "Mumbai  |  GPE  |  Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mr.Tata founded Tata Inc in 1868 in Mumbai\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9804772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
